# Modellverarbeitung und -vorhersagen
import torch
from torchvision import models, transforms
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from PIL import Image
import io
import os
import numpy as np
from utils import calculate_scale_factor, apply_nms
from image_preprocessing import preprocess_image

# Base directory für absolute Pfade
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# Absoluter Pfad zum Fast R-CNN Model
MODEL_PATH = os.path.join(BASE_DIR, 'fasterrcnn_model', 'fasterrcnn_model_2025-04-22-20-04-25.pth')

# Globale Variable für das Modell
model = None
device = None

def get_model(num_classes=6):
    """
    Erstellt und gibt ein Faster R-CNN Modell zurück.
    
    Args:
        num_classes: Anzahl der Klassen (inkl. Hintergrund)
        
    Returns:
        model: Das Modell-Objekt
    """
    model = models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    return model

def load_model():
    """
    Lädt das vortrainierte Modell aus der Modelldatei einmalig.
    
    Returns:
        model: Das geladene Modell-Objekt
    """
    global model, device
    # Überprüfen, ob das Modell bereits geladen wurde
    if model is None:
        print("Loading model for the first time...")
        device = torch.device('cpu')  # Force CPU für weniger RAM-Verbrauch
        model = get_model()
        
        if os.path.exists(MODEL_PATH):
            # Lade Model direkt auf CPU
            model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
            model.to(device)
            model.eval()
            print(f"Model loaded on {device}")
        else:
            raise FileNotFoundError(f"Model file '{MODEL_PATH}' not found")
    return model

def cleanup_memory():
    """
    Bereinigt nicht benötigten Speicher nach der Inferenz.
    """
    import gc
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

def resize_image_if_large(image, max_size=2048):
    """
    Verkleinert Bild wenn es zu groß ist, um RAM zu sparen.
    
    Args:
        image: PIL Image
        max_size: Maximale Bildgröße (längste Seite)
        
    Returns:
        resized_image: Verkleinertes Bild
        scale_factor: Skalierungsfaktor für Koordinaten-Rückkonvertierung
    """
    w, h = image.size
    max_dim = max(w, h)
    
    if max_dim > max_size:
        scale_factor = max_size / max_dim
        new_w = int(w * scale_factor)
        new_h = int(h * scale_factor)
        resized_image = image.resize((new_w, new_h), Image.Resampling.LANCZOS)
        return resized_image, 1/scale_factor
    
    return image, 1.0

def predict_image(image_bytes, format_size=(210, 297), dpi=300, plan_scale=100, threshold=0.5):
    """
    Führt memory-effiziente Objekterkennung auf einem Bild durch.
    
    Args:
        image_bytes: Bilddaten als Bytes
        format_size: Tuple (width, height) in mm
        dpi: Auflösung in Dots Per Inch
        plan_scale: Maßstab des Plans (z.B. 100 für 1:100)
        threshold: Schwellenwert für die Erkennungssicherheit
        
    Returns:
        boxes, labels, scores, areas: Arrays mit Erkennungsergebnissen
    """
    try:
        global device
        
        # Modell laden (nur einmal)
        model = load_model()
        
        # Vorverarbeitung mit OpenCV
        processed_image = preprocess_image(image_bytes)
        
        # Bild verkleinern falls zu groß
        processed_image, coord_scale = resize_image_if_large(processed_image, max_size=1024)
        
        # Bild transformieren (ohne extra .to(device) calls)
        transform = transforms.Compose([transforms.ToTensor()])
        image_tensor = transform(processed_image).unsqueeze(0)
        
        # Berechne den Umrechnungsfaktor
        pixels_per_meter = calculate_scale_factor(format_size, dpi, plan_scale)
        
        # Inferenz mit Memory-Cleanup
        with torch.no_grad():
            prediction = model(image_tensor)
        
        # Sofortiges Memory-Cleanup
        del image_tensor
        cleanup_memory()
        
        # Ergebnisse extrahieren
        boxes = prediction[0]['boxes'].cpu().numpy()
        labels = prediction[0]['labels'].cpu().numpy()
        scores = prediction[0]['scores'].cpu().numpy()
        
        # Koordinaten zurück skalieren falls Bild verkleinert wurde
        if coord_scale != 1.0:
            boxes = boxes * coord_scale
        
        # Schwellenwert anwenden
        valid_detections = scores >= threshold
        boxes = boxes[valid_detections]
        labels = labels[valid_detections]
        scores = scores[valid_detections]
        
        # Flächen berechnen
        areas = []
        for box in boxes:
            x1, y1, x2, y2 = box
            width_pixels = x2 - x1
            height_pixels = y2 - y1
            
            # Umrechnung in Meter
            width_meters = width_pixels / pixels_per_meter
            height_meters = height_pixels / pixels_per_meter
            
            # Fläche in m²
            area = width_meters * height_meters
            areas.append(area)
        
        # Non-Maximum Suppression anwenden
        boxes, labels, scores, areas = apply_nms(
            boxes, 
            labels, 
            scores, 
            areas, 
            iou_threshold=0.5,
            overlap_ratio_threshold=0.7,
            tolerance=5
        )
        
        # Final cleanup
        cleanup_memory()
        
        return boxes, labels, scores, areas
    
    except Exception as e:
        print(f"Error in predict_image: {e}")
        cleanup_memory()
        return [], [], [], []