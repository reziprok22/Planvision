# Modellverarbeitung und -vorhersagen
import torch
from torchvision import models, transforms
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from PIL import Image
import io
import os
import numpy as np
from utils import calculate_scale_factor, apply_nms
from image_preprocessing import preprocess_image

# Base directory f√ºr absolute Pfade
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# Absoluter Pfad zum Fast R-CNN Model
MODEL_PATH = os.path.join(BASE_DIR, 'fasterrcnn_model', 'fasterrcnn_model_2025-04-22-20-04-25.pth')

# Globale Variable f√ºr das Modell
model = None
device = None

def get_model(num_classes=6):
    """
    Erstellt und gibt ein Faster R-CNN Modell zur√ºck.
    
    Args:
        num_classes: Anzahl der Klassen (inkl. Hintergrund)
        
    Returns:
        model: Das Modell-Objekt
    """
    model = models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    return model

def load_model():
    """
    L√§dt das vortrainierte Modell aus der Modelldatei einmalig.
    Nutzt GPU falls verf√ºgbar f√ºr deutlich bessere Performance.
    
    Returns:
        model: Das geladene Modell-Objekt
    """
    global model, device
    # √úberpr√ºfen, ob das Modell bereits geladen wurde
    if model is None:
        print("Loading model for the first time...")
        
        # GPU-First Strategie: Nutze GPU falls verf√ºgbar, sonst CPU
        if torch.cuda.is_available():
            device = torch.device('cuda')
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            print(f"üöÄ GPU-Beschleunigung aktiviert: {gpu_name} ({gpu_memory:.1f}GB VRAM)")
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            device = torch.device('mps')
            print("üçé Apple Silicon MPS-Beschleunigung aktiviert")
        else:
            device = torch.device('cpu')
            print("‚ö†Ô∏è Keine GPU verf√ºgbar - nutze CPU (langsamer)")
        
        model = get_model()
        
        if os.path.exists(MODEL_PATH):
            # Lade Model-Gewichte auf das gew√§hlte Device
            print(f"Loading model weights on {device}...")
            model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
            model.to(device)
            model.eval()
            print(f"‚úÖ Model successfully loaded on {device}")
        else:
            raise FileNotFoundError(f"Model file '{MODEL_PATH}' not found")
    return model

def cleanup_memory():
    """
    Bereinigt nicht ben√∂tigten Speicher nach der Inferenz.
    Optimiert f√ºr GPU-Memory-Management.
    """
    import gc
    gc.collect()
    
    # GPU-Speicher bereinigen falls verf√ºgbar
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()  # Synchronisiere GPU-Operationen
    
    # MPS-Speicher bereinigen (Apple Silicon)
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        if hasattr(torch.mps, 'empty_cache'):
            torch.mps.empty_cache()

def resize_image_if_large(image, max_size=2048):
    """
    Verkleinert Bild wenn es zu gro√ü ist, um RAM zu sparen.
    
    Args:
        image: PIL Image
        max_size: Maximale Bildgr√∂√üe (l√§ngste Seite)
        
    Returns:
        resized_image: Verkleinertes Bild
        scale_factor: Skalierungsfaktor f√ºr Koordinaten-R√ºckkonvertierung
    """
    w, h = image.size
    max_dim = max(w, h)
    
    if max_dim > max_size:
        scale_factor = max_size / max_dim
        new_w = int(w * scale_factor)
        new_h = int(h * scale_factor)
        resized_image = image.resize((new_w, new_h), Image.Resampling.LANCZOS)
        return resized_image, 1/scale_factor
    
    return image, 1.0

def predict_image(image_bytes, format_size=(210, 297), dpi=300, plan_scale=100, threshold=0.5):
    """
    F√ºhrt memory-effiziente Objekterkennung auf einem Bild durch.
    
    Args:
        image_bytes: Bilddaten als Bytes
        format_size: Tuple (width, height) in mm
        dpi: Aufl√∂sung in Dots Per Inch
        plan_scale: Ma√üstab des Plans (z.B. 100 f√ºr 1:100)
        threshold: Schwellenwert f√ºr die Erkennungssicherheit
        
    Returns:
        boxes, labels, scores, areas: Arrays mit Erkennungsergebnissen
    """
    try:
        global device
        
        # Modell laden (nur einmal)
        model = load_model()
        
        # Vorverarbeitung mit OpenCV
        processed_image = preprocess_image(image_bytes)
        
        # Bild verkleinern falls zu gro√ü
        processed_image, coord_scale = resize_image_if_large(processed_image, max_size=1024)
        
        # Bild transformieren und direkt auf GPU verschieben
        transform = transforms.Compose([transforms.ToTensor()])
        image_tensor = transform(processed_image).unsqueeze(0).to(device)
        
        # Berechne den Umrechnungsfaktor
        pixels_per_meter = calculate_scale_factor(format_size, dpi, plan_scale)
        
        # GPU-optimierte Inferenz mit Memory-Management
        with torch.no_grad():
            prediction = model(image_tensor)
        
        # Sofortiges Memory-Cleanup f√ºr GPU-Effizienz
        del image_tensor
        if torch.cuda.is_available():
            torch.cuda.empty_cache()  # GPU-Cache sofort leeren
        
        # Ergebnisse extrahieren
        boxes = prediction[0]['boxes'].cpu().numpy()
        labels = prediction[0]['labels'].cpu().numpy()
        scores = prediction[0]['scores'].cpu().numpy()
        
        # Koordinaten zur√ºck skalieren falls Bild verkleinert wurde
        if coord_scale != 1.0:
            boxes = boxes * coord_scale
        
        # Schwellenwert anwenden
        valid_detections = scores >= threshold
        boxes = boxes[valid_detections]
        labels = labels[valid_detections]
        scores = scores[valid_detections]
        
        # Fl√§chen berechnen
        areas = []
        for box in boxes:
            x1, y1, x2, y2 = box
            width_pixels = x2 - x1
            height_pixels = y2 - y1
            
            # Umrechnung in Meter
            width_meters = width_pixels / pixels_per_meter
            height_meters = height_pixels / pixels_per_meter
            
            # Fl√§che in m¬≤
            area = width_meters * height_meters
            areas.append(area)
        
        # Non-Maximum Suppression anwenden
        boxes, labels, scores, areas = apply_nms(
            boxes, 
            labels, 
            scores, 
            areas, 
            iou_threshold=0.5,
            overlap_ratio_threshold=0.7,
            tolerance=5
        )
        
        # Final cleanup
        cleanup_memory()
        
        return boxes, labels, scores, areas
    
    except Exception as e:
        print(f"Error in predict_image: {e}")
        cleanup_memory()
        return [], [], [], []